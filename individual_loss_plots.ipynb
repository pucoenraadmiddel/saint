{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from data_openml import data_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "project_name = \"middelman/saint_rossmann_mse\"\n",
    "metric_name = \"orig_valid_rmse\"\n",
    "saint_runs = api.runs(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_saint_runs = sorted(\n",
    "    saint_runs, key=lambda r: r.summary.get(metric_name, float(\"inf\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_saint_runs[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('middelman/saint_rossmann_mse/SAINT_model_best_0wmepo8g:v0', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the best run from a sweep\n",
    "\n",
    "sweep_id = \"middelman/saint_rossmann_mse/ywy725ic\"\n",
    "\n",
    "sweep = api.sweep(sweep_id)\n",
    "\n",
    "best_run = sorted(\n",
    "    sweep.runs, key=lambda r: r.summary.get(metric_name, float(\"inf\"))\n",
    ")[0]\n",
    "\n",
    "print(best_run.summary[metric_name])\n",
    "print(best_run.id)\n",
    "print(best_run.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metadata for the run with the best metric\n",
    "import pprint\n",
    "# best_run = sorted_saint_runs[0]\n",
    "pprint.pprint(best_run.config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Reading the data...\")\n",
    "train = pd.read_parquet(\n",
    "    r\"/home/coenraadmiddel/Documents/RossmannStoreSales/TabNet/tabnet/train_processed.parquet\"\n",
    ")\n",
    "print(\"Read:\", train.shape)\n",
    "\n",
    "# select only a couple of columns\n",
    "\n",
    "train = train[\n",
    "    [\n",
    "        \"Store\",\n",
    "        \"DayOfWeek\",\n",
    "        \"Promo\",\n",
    "        \"StateHoliday\",\n",
    "        \"SchoolHoliday\",\n",
    "        \"StoreType\",\n",
    "        \"Assortment\",\n",
    "        \"CompetitionDistance\",\n",
    "        \"Promo2SinceWeek\",\n",
    "        \"Promo2SinceYear\",\n",
    "        \"Year\",\n",
    "        \"Month\",\n",
    "        \"Day\",\n",
    "        \"WeekOfYear\",\n",
    "        \"CompetitionOpen\",\n",
    "        \"PromoOpen\",\n",
    "        \"IsPromoMonth\",\n",
    "        \"Sales\",\n",
    "        \"Set\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "if \"Set\" not in train.columns:\n",
    "    train.reset_index(inplace=True, drop=True)\n",
    "    train[\"Set\"] = np.random.choice(\n",
    "        [\"train\", \"valid\", \"test\"], p=[0.8, 0.1, 0.1], size=(train.shape[0],)\n",
    "    )\n",
    "\n",
    "train_indices = train[train.Set == \"train\"].index\n",
    "valid_indices = train[train.Set == \"valid\"].index\n",
    "test_indices = train[train.Set == \"test\"].index\n",
    "\n",
    "\n",
    "categorical_columns = [\n",
    "    \"Store\",\n",
    "    \"DayOfWeek\",\n",
    "    \"Promo\",\n",
    "    \"StateHoliday\",\n",
    "    \"SchoolHoliday\",\n",
    "    \"StoreType\",\n",
    "    \"Assortment\",\n",
    "    # 'Year',\n",
    "    # 'Month',\n",
    "    # 'Day',\n",
    "    # 'WeekOfYear',\n",
    "    \"IsPromoMonth\",\n",
    "]\n",
    "\n",
    "\n",
    "# split x and y\n",
    "X_all, y_all = train.drop(columns=[\"Sales\", \"Set\"]), np.log1p(train[[\"Sales\"]].values)\n",
    "\n",
    "temp = X_all.fillna(\"MissingValue\")\n",
    "nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
    "\n",
    "X_train = X_all.iloc[train_indices]\n",
    "X_test = X_all.iloc[test_indices]\n",
    "X_valid = X_all.iloc[valid_indices]\n",
    "\n",
    "y_train = y_all[train_indices]\n",
    "y_test = y_all[test_indices]\n",
    "y_valid = y_all[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is SAINT specific...\n",
    "# temp = X_all.fillna(\"MissingValue\")\n",
    "# nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
    "\n",
    "X_train_d, y_train_d = data_split(X_all, y_all, nan_mask, train_indices)\n",
    "X_valid_d, y_valid_d = data_split(X_all, y_all, nan_mask, valid_indices)\n",
    "X_test_d, y_test_d = data_split(X_all, y_all, nan_mask, test_indices)\n",
    "\n",
    "X_train = X_train_d['data']\n",
    "X_test = X_test_d['data']\n",
    "X_valid = X_valid_d['data']\n",
    "\n",
    "y_train = y_train_d['data']\n",
    "y_test = y_test_d['data']\n",
    "y_valid = y_valid_d['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[categorical_columns] = train[categorical_columns].astype('category')\n",
    "\n",
    "cat_idxs = [train.columns.get_loc(c) for c in categorical_columns if c in train]\n",
    "cat_dims = [len(train[c].cat.categories) for c in categorical_columns if c in train]\n",
    "cont_idxs = [i for i in range(X_train.shape[1]) if i not in cat_idxs]\n",
    "\n",
    "train_mean, train_std = np.array(X_train_d['data'][:,cont_idxs],dtype=np.float32).mean(0), np.array(X_train_d['data'][:,cont_idxs],dtype=np.float32).std(0)\n",
    "continuous_mean_std = np.array([train_mean, train_std]).astype(np.float32) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load the SAINT model\n",
    "from models import SAINT\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using {}\".format(device))\n",
    "\n",
    "\n",
    "#changes to the model inputs. NB\n",
    "cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings.\n",
    "\n",
    "\n",
    "model = SAINT(\n",
    "    categories = cat_dims,\n",
    "    num_continuous = len(cont_idxs),\n",
    "    dim = best_run.config['embedding_size'],\n",
    "    dim_out = 1,\n",
    "    depth = best_run.config['transformer_depth'],\n",
    "    heads = best_run.config['attention_heads'],\n",
    "    attn_dropout = best_run.config['attention_dropout'],\n",
    "    ff_dropout = best_run.config['ff_dropout'],\n",
    "    mlp_hidden_mults = (4, 2),\n",
    "    cont_embeddings = best_run.config['cont_embeddings'],\n",
    "    attentiontype = best_run.config['attentiontype'],\n",
    "    final_mlp_style = best_run.config['final_mlp_style'],\n",
    "    y_dim = 1,\n",
    ")\n",
    "    \n",
    "criterion = nn.MSELoss().to(device)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('/home/coenraadmiddel/Documents/RossmannStoreSales/SAINT/saint/bestmodels/regression/rossmann_local/SAINT_model_best_0wmepo8g.pt'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_openml import DataSetCatCon\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import count_parameters, classification_scores, mean_sq_error\n",
    "\n",
    "\n",
    "valid_ds = DataSetCatCon(X_valid_d, y_valid_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "# validloader = DataLoader(valid_ds, batch_size=best_run.config['batchsize'], shuffle=False)\n",
    "validloader = DataLoader(valid_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from utils import mean_sq_error_per_sample\n",
    "\n",
    "losses = mean_sq_error_per_sample(model, validloader, device, vision_dset=True)\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the test data\n",
    "test = pd.read_parquet(r'/home/coenraadmiddel/Documents/RossmannStoreSales/TabNet/tabnet/test_processed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>CompetitionOpen</th>\n",
       "      <th>PromoOpen</th>\n",
       "      <th>IsPromoMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.0</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>427.500000</td>\n",
       "      <td>2.979167</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.443487</td>\n",
       "      <td>1.252336</td>\n",
       "      <td>1.001168</td>\n",
       "      <td>5076.693925</td>\n",
       "      <td>14.182243</td>\n",
       "      <td>1168.078271</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.354167</td>\n",
       "      <td>13.520833</td>\n",
       "      <td>34.645833</td>\n",
       "      <td>9006.475662</td>\n",
       "      <td>10168.176645</td>\n",
       "      <td>0.127434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>247.108754</td>\n",
       "      <td>2.015481</td>\n",
       "      <td>0.489035</td>\n",
       "      <td>0.066044</td>\n",
       "      <td>0.496802</td>\n",
       "      <td>1.397401</td>\n",
       "      <td>0.994741</td>\n",
       "      <td>7221.221850</td>\n",
       "      <td>16.177932</td>\n",
       "      <td>992.765386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478266</td>\n",
       "      <td>8.448450</td>\n",
       "      <td>2.015481</td>\n",
       "      <td>11643.213793</td>\n",
       "      <td>11916.197620</td>\n",
       "      <td>0.333462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>213.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>710.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>427.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2410.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>641.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6435.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>24188.000000</td>\n",
       "      <td>24188.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>855.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75860.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>24189.000000</td>\n",
       "      <td>24189.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store     DayOfWeek         Promo  StateHoliday  SchoolHoliday  \\\n",
       "count  41088.000000  41088.000000  41088.000000  41088.000000   41088.000000   \n",
       "mean     427.500000      2.979167      0.395833      0.004381       0.443487   \n",
       "std      247.108754      2.015481      0.489035      0.066044       0.496802   \n",
       "min        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%      213.750000      1.000000      0.000000      0.000000       0.000000   \n",
       "50%      427.500000      3.000000      0.000000      0.000000       0.000000   \n",
       "75%      641.250000      5.000000      1.000000      0.000000       1.000000   \n",
       "max      855.000000      6.000000      1.000000      1.000000       1.000000   \n",
       "\n",
       "          StoreType    Assortment  CompetitionDistance  Promo2SinceWeek  \\\n",
       "count  41088.000000  41088.000000         41088.000000     41088.000000   \n",
       "mean       1.252336      1.001168          5076.693925        14.182243   \n",
       "std        1.397401      0.994741          7221.221850        16.177932   \n",
       "min        0.000000      0.000000             0.000000         0.000000   \n",
       "25%        0.000000      0.000000           710.000000         0.000000   \n",
       "50%        0.000000      1.000000          2410.000000         9.000000   \n",
       "75%        3.000000      2.000000          6435.000000        31.000000   \n",
       "max        3.000000      2.000000         75860.000000        49.000000   \n",
       "\n",
       "       Promo2SinceYear     Year         Month           Day    WeekOfYear  \\\n",
       "count     41088.000000  41088.0  41088.000000  41088.000000  41088.000000   \n",
       "mean       1168.078271   2015.0      8.354167     13.520833     34.645833   \n",
       "std         992.765386      0.0      0.478266      8.448450      2.015481   \n",
       "min           0.000000   2015.0      8.000000      1.000000     31.000000   \n",
       "25%           0.000000   2015.0      8.000000      6.750000     33.000000   \n",
       "50%        2010.000000   2015.0      8.000000     12.500000     35.000000   \n",
       "75%        2012.000000   2015.0      9.000000     19.250000     36.000000   \n",
       "max        2015.000000   2015.0      9.000000     31.000000     38.000000   \n",
       "\n",
       "       CompetitionOpen     PromoOpen  IsPromoMonth  \n",
       "count     41088.000000  41088.000000  41088.000000  \n",
       "mean       9006.475662  10168.176645      0.127434  \n",
       "std       11643.213793  11916.197620      0.333462  \n",
       "min           0.000000      2.000000      0.000000  \n",
       "25%          47.000000     34.250000      0.000000  \n",
       "50%         119.000000     66.250000      0.000000  \n",
       "75%       24188.000000  24188.500000      0.000000  \n",
       "max       24189.000000  24189.500000      1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe(include=\"all\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is SAINT specific...\n",
    "temp = test.fillna(\"MissingValue\")\n",
    "nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
    "testy = np.zeros((test.shape[0],1))\n",
    "\n",
    "X_testtest_d, y_test_d = data_split(test, testy, nan_mask, test.index)\n",
    "\n",
    "X_testtest = X_test_d['data']\n",
    "\n",
    "y_testtest = y_test_d['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testy is an array with 0's with the same shape as test\n",
    "testtest_ds = DataSetCatCon(X_testtest_d, y_test_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "testtestloader = DataLoader(testtest_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import predict\n",
    "\n",
    "validloader = DataLoader(valid_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "# preds = predict(model, validloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, testtestloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(preds, columns=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the preditions as integers\n",
    "df_preds['preds'] = df_preds['preds'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'Id': df_preds.index+1, 'Sales': df_preds['preds']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(r'/home/coenraadmiddel/Documents/RossmannStoreSales/SAINT/saint/submission.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the randomness of the data, check the indices of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = DataSetCatCon(X_train_d, y_train_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "trainloader = DataLoader(train_ds, batch_size=best_run.config['batchsize'], shuffle=True)\n",
    "\n",
    "valid_ds = DataSetCatCon(X_valid_d, y_valid_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "validloader = DataLoader(valid_ds, batch_size=best_run.config['batchsize'], shuffle=False)\n",
    "\n",
    "test_ds = DataSetCatCon(X_test_d, y_test_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "testloader = DataLoader(test_ds, batch_size=best_run.config['batchsize'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_dset = best_run.config['vision_dset']\n",
    "with torch.no_grad():\n",
    "    valid_rmse, orig_valid_rmse, valid_losses = mean_sq_error(model, validloader, device, vision_dset, batch_wise=True)\n",
    "    test_rmse, orig_test_rmse, test_losses= mean_sq_error(model, testloader, device, vision_dset, batch_wise=True)\n",
    "    train_rmse, orig_train_rmse, orig_losses = mean_sq_error(model, trainloader, device, vision_dset, batch_wise=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mean of the valid_losses list\n",
    "\n",
    "df_losses = pd.DataFrame({'valid_losses':valid_losses})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_losses['valid_losses'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VALID RMSE: %.3f, ORIG VALID RMSE: %.3f' %\n",
    "    (valid_rmse, orig_valid_rmse ))\n",
    "print('TEST RMSE: %.3f, ORIG TEST RMSE: %.3f' %\n",
    "    (test_rmse, orig_test_rmse ))\n",
    "print('TRAIN RMSE: %.3f, ORIG TRAIN RMSE: %.3f' %\n",
    "    (train_rmse, orig_train_rmse ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save losses as a parquet file\n",
    "df = pd.DataFrame({'losses':valid_losses})\n",
    "\n",
    "df.to_parquet('/home/coenraadmiddel/Documents/RossmannStoreSales/SAINT/saint/saint_losses.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saint_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
