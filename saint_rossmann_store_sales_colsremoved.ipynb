{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coenraadmiddel/miniconda3/envs/saint_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804056, 19)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(r'/home/coenraadmiddel/Documents/RossmannStoreSales/TabNet/tabnet/train_processed.parquet')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Store',\n",
       " 'DayOfWeek',\n",
       " 'Promo',\n",
       " 'StateHoliday',\n",
       " 'SchoolHoliday',\n",
       " 'StoreType',\n",
       " 'Assortment',\n",
       " 'CompetitionDistance',\n",
       " 'Promo2SinceWeek',\n",
       " 'Promo2SinceYear',\n",
       " 'Year',\n",
       " 'Month',\n",
       " 'Day',\n",
       " 'WeekOfYear',\n",
       " 'CompetitionOpen',\n",
       " 'PromoOpen',\n",
       " 'IsPromoMonth',\n",
       " 'Sales',\n",
       " 'Set']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only a couple of columns\n",
    "\n",
    "train = train[['Store',\n",
    "                'DayOfWeek',\n",
    "                'Promo',\n",
    "                'StateHoliday',\n",
    "                'SchoolHoliday',\n",
    "                'StoreType',\n",
    "                'Assortment',\n",
    "                'CompetitionDistance',\n",
    "                'Promo2SinceWeek',\n",
    "                'Promo2SinceYear',\n",
    "                'Year',\n",
    "                'Month',\n",
    "                'Day',\n",
    "                'WeekOfYear',\n",
    "                'CompetitionOpen',\n",
    "                'PromoOpen',\n",
    "                'IsPromoMonth',\n",
    "                'Sales',\n",
    "                'Set']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "if \"Set\" not in train.columns:\n",
    "    train.reset_index(inplace=True, drop=True)\n",
    "    train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "train_indices = train[train.Set==\"train\"].index\n",
    "valid_indices = train[train.Set==\"valid\"].index\n",
    "test_indices = train[train.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coenraadmiddel/miniconda3/envs/saint_env/lib/python3.8/site-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/coenraadmiddel/miniconda3/envs/saint_env/lib/python3.8/site-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check distribution of sales in train set\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "g1 = sns.distplot(train['Sales'],hist = True,label='skewness:{:.2f}'.format(train['Sales'].skew()),ax = ax1)\n",
    "g1.legend()\n",
    "g1.set(xlabel = 'Sales', \n",
    "\n",
    "ylabel = 'Density', title = 'Sales Distribution')\n",
    "g2 = sns.distplot(np.log1p(train['Sales']),hist = True,label='skewness:{:.2f}'.format(np.log1p(train['Sales']).skew()),ax=ax2)\n",
    "g2.legend()\n",
    "g2.set(xlabel = 'log(Sales+1)',ylabel = 'Density', title = 'log(Sales+1) Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "categorical_columns = ['Store',\n",
    "                        'DayOfWeek',\n",
    "                        'Promo',\n",
    "                        'StateHoliday',\n",
    "                        'SchoolHoliday',\n",
    "                        'StoreType',\n",
    "                        'Assortment',\n",
    "                        # 'Year',\n",
    "                        # 'Month',\n",
    "                        # 'Day',\n",
    "                        # 'WeekOfYear',\n",
    "                        'IsPromoMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      4,      5,      6,      8,      9,\n",
       "                10,     11,\n",
       "            ...\n",
       "            804043, 804045, 804046, 804047, 804048, 804049, 804051, 804052,\n",
       "            804054, 804055],\n",
       "           dtype='int64', length=643484)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_openml import data_split\n",
    "\n",
    "# split x and y\n",
    "X_all, y_all = train.drop(columns = ['Sales', 'Set']), np.log1p(train[['Sales']].values)\n",
    "\n",
    "temp = X_all.fillna(\"MissingValue\")\n",
    "nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
    "\n",
    "X_train_d, y_train_d = data_split(X_all, y_all, nan_mask, train_indices)\n",
    "X_valid_d, y_valid_d = data_split(X_all, y_all, nan_mask, valid_indices)\n",
    "X_test_d, y_test_d = data_split(X_all, y_all, nan_mask, test_indices)\n",
    "\n",
    "\n",
    "X_train = X_train_d['data']\n",
    "X_test = X_test_d['data']\n",
    "X_valid = X_valid_d['data']\n",
    "\n",
    "y_train = y_train_d['data']\n",
    "y_test = y_test_d['data']\n",
    "y_valid = y_valid_d['data']\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X_all.values[train_indices]\n",
    "# y_train = y_all.values[train_indices].reshape(-1, 1)\n",
    "\n",
    "# X_valid = X_all.values[valid_indices]\n",
    "# y_valid = y_all.values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "# X_test = X_all.values[test_indices]\n",
    "# y_test = y_all.values[test_indices].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'dict'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "print(type(y_train_d))\n",
    "print(type(X_train))\n",
    "print(type(X_train_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force categorical columns to the categorical type\n",
    "\n",
    "train[categorical_columns] = train[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get the indices of the categorical columns in train dataFrame\n",
    "\n",
    "cat_idxs = [train.columns.get_loc(c) for c in categorical_columns if c in train]\n",
    "\n",
    "#get the dimensions of the categorical columns in train dataFrame\n",
    "\n",
    "cat_dims = [len(train[c].cat.categories) for c in categorical_columns if c in train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 16]\n",
      "[1115, 7, 2, 4, 2, 4, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(cat_idxs)\n",
    "print(cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SAINT\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiddelman\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/coenraadmiddel/Documents/RossmannStoreSales/SAINT/saint/wandb/run-20230530_110032-t68n63ni</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/middelman/saint_v2_all_rossmann/runs/t68n63ni' target=\"_blank\">regression_colrow_rossmann_seed42</a></strong> to <a href='https://wandb.ai/middelman/saint_v2_all_rossmann' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/middelman/saint_v2_all_rossmann' target=\"_blank\">https://wandb.ai/middelman/saint_v2_all_rossmann</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/middelman/saint_v2_all_rossmann/runs/t68n63ni' target=\"_blank\">https://wandb.ai/middelman/saint_v2_all_rossmann/runs/t68n63ni</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/middelman/saint_v2_all_rossmann/runs/t68n63ni?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7240c864c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.init(project=\"saint_v2_all_rossmann\", group = \"first\" ,name = f'regression_colrow_rossmann_seed42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument('--dset_id', required=True, type=int)\n",
    "parser.add_argument('--vision_dset', action = 'store_true')\n",
    "parser.add_argument('--task', default='regression', type=str,choices = ['binary','multiclass','regression'])\n",
    "parser.add_argument('--cont_embeddings', default='MLP', type=str,choices = ['MLP','Noemb','pos_singleMLP'])\n",
    "parser.add_argument('--embedding_size', default=32, type=int)\n",
    "parser.add_argument('--transformer_depth', default=6, type=int)\n",
    "parser.add_argument('--attention_heads', default=3, type=int)\n",
    "parser.add_argument('--attention_dropout', default=0.1, type=float)\n",
    "parser.add_argument('--ff_dropout', default=0.1, type=float)\n",
    "parser.add_argument('--attentiontype', default='colrow', type=str,choices = ['col','colrow','row','justmlp','attn','attnmlp'])\n",
    "\n",
    "parser.add_argument('--optimizer', default='AdamW', type=str,choices = ['AdamW','Adam','SGD'])\n",
    "parser.add_argument('--scheduler', default='cosine', type=str,choices = ['cosine','linear'])\n",
    "\n",
    "parser.add_argument('--lr', default=0.00001, type=float)\n",
    "parser.add_argument('--epochs', default=10, type=int)\n",
    "parser.add_argument('--batchsize', default=256, type=int)\n",
    "parser.add_argument('--savemodelroot', default='./bestmodels', type=str)\n",
    "parser.add_argument('--run_name', default='testrun', type=str)\n",
    "parser.add_argument('--set_seed', default= 42 , type=int)\n",
    "parser.add_argument('--dset_seed', default= 42 , type=int)\n",
    "parser.add_argument('--active_log', action = 'store_true')\n",
    "\n",
    "parser.add_argument('--pretrain', action = 'store_true')\n",
    "parser.add_argument('--pretrain_epochs', default=50, type=int)\n",
    "parser.add_argument('--pt_tasks', default=['contrastive','denoising'], type=str,nargs='*',choices = ['contrastive','contrastive_sim','denoising'])\n",
    "parser.add_argument('--pt_aug', default=[], type=str,nargs='*',choices = ['mixup','cutmix'])\n",
    "parser.add_argument('--pt_aug_lam', default=0.1, type=float)\n",
    "parser.add_argument('--mixup_lam', default=0.3, type=float)\n",
    "\n",
    "parser.add_argument('--train_mask_prob', default=0, type=float)\n",
    "parser.add_argument('--mask_prob', default=0, type=float)\n",
    "\n",
    "parser.add_argument('--ssl_avail_y', default= 0, type=int)\n",
    "parser.add_argument('--pt_projhead_style', default='diff', type=str,choices = ['diff','same','nohead'])\n",
    "parser.add_argument('--nce_temp', default=0.7, type=float)\n",
    "\n",
    "parser.add_argument('--lam0', default=0.5, type=float)\n",
    "parser.add_argument('--lam1', default=10, type=float)\n",
    "parser.add_argument('--lam2', default=1, type=float)\n",
    "parser.add_argument('--lam3', default=10, type=float)\n",
    "parser.add_argument('--final_mlp_style', default='sep', type=str,choices = ['common','sep'])\n",
    "\n",
    "\n",
    "opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.attention_heads = min(4, opt.attention_heads)\n",
    "opt.attention_dropout = 0.8\n",
    "opt.embedding_size = min(32, opt.embedding_size)\n",
    "opt.ff_dropout = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(opt)\n",
    "#for regression this is the output dimension\n",
    "y_dim = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# get the con_idxs and cat_idxs\n",
    "\n",
    "cont_idxs = [i for i in range(X_train.shape[1]) if i not in cat_idxs]\n",
    "print(cont_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = np.array(X_train_d['data'][:,cont_idxs],dtype=np.float32).mean(0), np.array(X_train_d['data'][:,cont_idxs],dtype=np.float32).std(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_dims= (1, 1115, 7, 2, 4, 2, 4, 3, 2)\n",
      "num_continuous = 9\n",
      "dim = 32\n",
      "dim_out = 1\n",
      "depth = 6\n",
      "heads = 3\n",
      "attn_dropout = 0.8\n",
      "ff_dropout = 0.8\n",
      "mlp_hidden_mults = (4, 2)\n",
      "cont_embeddings = MLP\n",
      "attentiontype = colrow\n",
      "final_mlp_style = sep\n",
      "y_dim = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"cat_dims=\", tuple(cat_dims) )\n",
    "print(\"num_continuous =\", len(cont_idxs))\n",
    "print(\"dim =\", opt.embedding_size)\n",
    "print(\"dim_out =\", 1)\n",
    "print(\"depth =\", opt.transformer_depth)\n",
    "print(\"heads =\", opt.attention_heads)\n",
    "print(\"attn_dropout =\", opt.attention_dropout)\n",
    "print(\"ff_dropout =\", opt.ff_dropout)\n",
    "print(\"mlp_hidden_mults =\", (4, 2))\n",
    "print(\"cont_embeddings =\", opt.cont_embeddings)\n",
    "print(\"attentiontype =\", opt.attentiontype)\n",
    "print(\"final_mlp_style =\", opt.final_mlp_style)\n",
    "print(\"y_dim =\", y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(active_log=False, attention_dropout=0.8, attention_heads=3, attentiontype='colrow', batchsize=256, cont_embeddings='MLP', dset_seed=42, embedding_size=32, epochs=10, ff_dropout=0.8, final_mlp_style='sep', lam0=0.5, lam1=10, lam2=1, lam3=10, lr=1e-05, mask_prob=0, mixup_lam=0.3, nce_temp=0.7, optimizer='AdamW', pretrain=False, pretrain_epochs=50, pt_aug=[], pt_aug_lam=0.1, pt_projhead_style='diff', pt_tasks=['contrastive', 'denoising'], run_name='testrun', savemodelroot='./bestmodels', scheduler='cosine', set_seed=42, ssl_avail_y=0, task='regression', train_mask_prob=0, transformer_depth=6, vision_dset=False)\n"
     ]
    }
   ],
   "source": [
    "print(opt)\n",
    "model = SAINT(categories = tuple(cat_dims), \n",
    "                num_continuous = len(cont_idxs),                \n",
    "                dim = opt.embedding_size,                           \n",
    "                dim_out = 1,                       \n",
    "                depth = opt.transformer_depth,                       \n",
    "                heads = opt.attention_heads,                         \n",
    "                attn_dropout = opt.attention_dropout,             \n",
    "                ff_dropout = opt.ff_dropout,                  \n",
    "                mlp_hidden_mults = (4, 2),       \n",
    "                cont_embeddings = opt.cont_embeddings,\n",
    "                attentiontype = opt.attentiontype,\n",
    "                final_mlp_style = opt.final_mlp_style,\n",
    "                y_dim = y_dim\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (norm): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
       "  (simple_MLP): ModuleList(\n",
       "    (0): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer): RowColTransformer(\n",
       "    (embeds): Embedding(1140, 32)\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mask_embed): Embedding(18, 32)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=288, bias=True)\n",
       "      (1): Linear(in_features=288, out_features=144, bias=True)\n",
       "      (2): Linear(in_features=144, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (embeds): Embedding(1140, 32)\n",
       "  (mask_embeds_cat): Embedding(18, 32)\n",
       "  (mask_embeds_cont): Embedding(18, 32)\n",
       "  (single_mask): Embedding(2, 32)\n",
       "  (pos_encodings): Embedding(18, 32)\n",
       "  (mlp1): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1115, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=7, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp2): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlpfory): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=1000, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=691, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=691, out_features=288, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp2): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=691, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=691, out_features=288, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss().to(device)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the optimizer:  AdamW\n",
      "Training begins now.\n"
     ]
    }
   ],
   "source": [
    "## Choosing the optimizer\n",
    "import torch.optim as optim\n",
    "if opt.optimizer == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=opt.lr,\n",
    "                          momentum=0.9, weight_decay=5e-4)\n",
    "    from utils import get_scheduler\n",
    "    scheduler = get_scheduler(opt, optimizer)\n",
    "elif opt.optimizer == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(),lr=opt.lr)\n",
    "elif opt.optimizer == 'AdamW':\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=opt.lr)\n",
    "best_valid_auroc = 0\n",
    "best_valid_accuracy = 0\n",
    "best_test_auroc = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_rmse = 100000\n",
    "print('Using the optimizer: ', opt.optimizer)\n",
    "print('Training begins now.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_openml import DataSetCatCon\n",
    "\n",
    "continuous_mean_std = np.array([train_mean, train_std]).astype(np.float32) \n",
    "\n",
    "train_ds = DataSetCatCon(X_train_d, y_train_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "trainloader = DataLoader(train_ds, batch_size=opt.batchsize, shuffle=True)\n",
    "\n",
    "valid_ds = DataSetCatCon(X_valid_d, y_valid_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "validloader = DataLoader(valid_ds, batch_size=opt.batchsize, shuffle=False)\n",
    "\n",
    "test_ds = DataSetCatCon(X_test_d, y_test_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "testloader = DataLoader(test_ds, batch_size=opt.batchsize, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.pretrain:\n",
    "    from pretraining import SAINT_pretrain\n",
    "    model = SAINT_pretrain(model, cat_idxs,X_train,y_train, continuous_mean_std, opt,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 1] VALID RMSE: 0.748\n",
      "[EPOCH 1] TEST RMSE: 0.748\n",
      "[EPOCH 6] VALID RMSE: 0.312\n",
      "[EPOCH 6] TEST RMSE: 0.310\n"
     ]
    }
   ],
   "source": [
    "from augmentations import embed_data_mask\n",
    "from utils import count_parameters, classification_scores, mean_sq_error\n",
    "import os\n",
    "\n",
    "modelsave_path = os.path.join(opt.savemodelroot,opt.run_name)\n",
    "\n",
    "vision_dset = opt.vision_dset\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        # x_categ is the the categorical data, x_cont has continuous data, y_gts has ground truth ys. cat_mask is an array of ones same shape as x_categ and an additional column(corresponding to CLS token) set to 0s. \n",
    "        # con_mask is an array of ones same shape as x_cont. \n",
    "        x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device), data[2].to(device), data[3].to(device),data[4].to(device)\n",
    "\n",
    "        # We are converting the data to embeddings in the next step\n",
    "        _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model)           \n",
    "        \n",
    "        reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "        # select only the representations corresponding to CLS token and apply mlp on it in the next step to get the predictions.\n",
    "        y_reps = reps[:,0,:]\n",
    "        \n",
    "        y_outs = model.mlpfory(y_reps)\n",
    "        if opt.task == 'regression':\n",
    "            loss = criterion(y_outs, y_gts) \n",
    "        else:\n",
    "            loss = criterion(y_outs,y_gts.squeeze()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if opt.optimizer == 'SGD':\n",
    "            scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "    # print(running_loss)\n",
    "    if opt.active_log:\n",
    "        wandb.log({'epoch': epoch ,'train_epoch_loss': running_loss, \n",
    "        'loss': loss.item()\n",
    "        })\n",
    "    if epoch%5==0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_rmse = mean_sq_error(model, validloader, device, vision_dset)    \n",
    "                test_rmse = mean_sq_error(model, testloader, device, vision_dset)  \n",
    "                print('[EPOCH %d] VALID RMSE: %.3f' % (epoch + 1, valid_rmse[0]))\n",
    "                print('[EPOCH %d] TEST RMSE: %.3f' % (epoch + 1, test_rmse[0]))\n",
    "\n",
    "                if opt.active_log:\n",
    "                    wandb.log({'valid_rmse': valid_rmse ,'test_rmse': test_rmse })   \n",
    "                # import ipdb; ipdb.set_trace()  \n",
    "                if valid_rmse[0] < best_valid_rmse:\n",
    "                    best_valid_rmse = valid_rmse[0]\n",
    "                    best_test_rmse = test_rmse[0]\n",
    "                    torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (norm): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
       "  (simple_MLP): ModuleList(\n",
       "    (0): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer): RowColTransformer(\n",
       "    (embeds): Embedding(1140, 32)\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mask_embed): Embedding(18, 32)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=288, bias=True)\n",
       "      (1): Linear(in_features=288, out_features=144, bias=True)\n",
       "      (2): Linear(in_features=144, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (embeds): Embedding(1140, 32)\n",
       "  (mask_embeds_cat): Embedding(18, 32)\n",
       "  (mask_embeds_cont): Embedding(18, 32)\n",
       "  (single_mask): Embedding(2, 32)\n",
       "  (pos_encodings): Embedding(18, 32)\n",
       "  (mlp1): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1115, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=7, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp2): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlpfory): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=1000, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=691, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=691, out_features=288, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp2): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=691, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=691, out_features=288, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model from the best model\n",
    "\n",
    "model.load_state_dict(torch.load('/home/coenraadmiddel/Documents/RossmannStoreSales/SAINT/saint/bestmodels/testrun/bestmodel.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.48735235],\n",
       "       [8.62927109],\n",
       "       [8.31483218],\n",
       "       ...,\n",
       "       [8.16876982],\n",
       "       [8.56483984],\n",
       "       [8.42090253]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SAINT' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31176/2812302708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/saint_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1270\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SAINT' object has no attribute 'predict'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = model.predict(X_valid.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the dataloader to load each instance and get an instance specific loss value\n",
    "\n",
    "losses = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SAINT' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31176/2812302708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/saint_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1270\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SAINT' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "losses = [mean_squared_error([true], [pred], squared=False) for true, pred in zip(np.expm1(y_valid), y_valid_pred)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvRossmann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
