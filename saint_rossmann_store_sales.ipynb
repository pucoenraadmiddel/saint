{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3042183125.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_31454/3042183125.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    = pd.read_parquet(r'/home/coenraadmiddel/Documents/RossmannStoreSales/TabNet/tabnet/train_processed.parquet')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(r'/home/coenraadmiddel/Documents/RossmannStoreSales/TabNet/tabnet/train_processed.parquet')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12782/1310172698.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#select only a couple of columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train = train[['Store','DayOfWeek'\n\u001b[0m\u001b[1;32m      4\u001b[0m                \u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Customers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Promo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'StateHoliday'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0;34m,\u001b[0m\u001b[0;34m'SchoolHoliday'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'StoreType'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Assortment'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CompetitionDistance'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CompetitionOpenSinceMonth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#select only a couple of columns\n",
    "\n",
    "#This was done to figure out why there is a categorical dim issue when training. (Because of missing code, see notes.)\n",
    "\n",
    "train = train[['Store','DayOfWeek'\n",
    "               ,'Date','Sales','Customers','Open','Promo','StateHoliday'\n",
    "               ,'SchoolHoliday','StoreType','Assortment','CompetitionDistance','CompetitionOpenSinceMonth'\n",
    "               ,'CompetitionOpenSinceYear','Promo2','Promo2SinceWeek','Promo2SinceYear','PromoInterval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "if \"Set\" not in train.columns:\n",
    "    train.reset_index(inplace=True, drop=True)\n",
    "    train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "train_indices = train[train.Set==\"train\"].index\n",
    "valid_indices = train[train.Set==\"valid\"].index\n",
    "test_indices = train[train.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check distribution of sales in train set\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "g1 = sns.distplot(train['Sales'],hist = True,label='skewness:{:.2f}'.format(train['Sales'].skew()),ax = ax1)\n",
    "g1.legend()\n",
    "g1.set(xlabel = 'Sales', \n",
    "\n",
    "ylabel = 'Density', title = 'Sales Distribution')\n",
    "g2 = sns.distplot(np.log1p(train['Sales']),hist = True,label='skewness:{:.2f}'.format(np.log1p(train['Sales']).skew()),ax=ax2)\n",
    "g2.legend()\n",
    "g2.set(xlabel = 'log(Sales+1)',ylabel = 'Density', title = 'log(Sales+1) Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "categorical_columns = ['Store',\n",
    "                        'DayOfWeek',\n",
    "                        'Promo',\n",
    "                        'StateHoliday',\n",
    "                        'SchoolHoliday',\n",
    "                        'StoreType',\n",
    "                        'Assortment',\n",
    "                        # 'Year',\n",
    "                        # 'Month',\n",
    "                        # 'Day',\n",
    "                        # 'WeekOfYear',\n",
    "                        'IsPromoMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_openml import data_split\n",
    "\n",
    "# split x and y\n",
    "X_all, y_all = train.drop(columns = ['Sales', 'Set']), np.log1p(train[['Sales']].values)\n",
    "\n",
    "temp = X_all.fillna(\"MissingValue\")\n",
    "nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
    "\n",
    "X_train_d, y_train_d = data_split(X_all, y_all, nan_mask, train_indices)\n",
    "X_valid_d, y_valid_d = data_split(X_all, y_all, nan_mask, valid_indices)\n",
    "X_test_d, y_test_d = data_split(X_all, y_all, nan_mask, test_indices)\n",
    "\n",
    "\n",
    "X_train = X_train_d['data']\n",
    "X_test = X_test_d['data']\n",
    "X_valid = X_valid_d['data']\n",
    "\n",
    "y_train = y_train_d['data']\n",
    "y_test = y_test_d['data']\n",
    "y_valid = y_valid_d['data']\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X_all.values[train_indices]\n",
    "# y_train = y_all.values[train_indices].reshape(-1, 1)\n",
    "\n",
    "# X_valid = X_all.values[valid_indices]\n",
    "# y_valid = y_all.values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "# X_test = X_all.values[test_indices]\n",
    "# y_test = y_all.values[test_indices].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_train))\n",
    "print(type(y_train_d))\n",
    "print(type(X_train))\n",
    "print(type(X_train_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2, 2, 2, 2, 2]\n",
    "cat_idxs = [0, 1, 2, 3, 4, 5, 6, 16]\n",
    "cat_dims = [1115, 7, 2, 4, 2, 4, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SAINT\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.init(project=\"saint_v2_all_rossmann\", group = \"first\" ,name = f'regression_colrow_rossmann_seed42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument('--dset_id', required=True, type=int)\n",
    "# parser.add_argument('--vision_dset', action = 'store_true')\n",
    "# parser.add_argument('--task', required=True, type=str,choices = ['binary','multiclass','regression'])\n",
    "parser.add_argument('--cont_embeddings', default='MLP', type=str,choices = ['MLP','Noemb','pos_singleMLP'])\n",
    "parser.add_argument('--embedding_size', default=32, type=int)\n",
    "parser.add_argument('--transformer_depth', default=6, type=int)\n",
    "parser.add_argument('--attention_heads', default=8, type=int)\n",
    "parser.add_argument('--attention_dropout', default=0.1, type=float)\n",
    "parser.add_argument('--ff_dropout', default=0.1, type=float)\n",
    "parser.add_argument('--attentiontype', default='colrow', type=str,choices = ['col','colrow','row','justmlp','attn','attnmlp'])\n",
    "\n",
    "parser.add_argument('--optimizer', default='AdamW', type=str,choices = ['AdamW','Adam','SGD'])\n",
    "parser.add_argument('--scheduler', default='cosine', type=str,choices = ['cosine','linear'])\n",
    "\n",
    "parser.add_argument('--lr', default=0.0001, type=float)\n",
    "parser.add_argument('--epochs', default=100, type=int)\n",
    "parser.add_argument('--batchsize', default=256, type=int)\n",
    "parser.add_argument('--savemodelroot', default='./bestmodels', type=str)\n",
    "parser.add_argument('--run_name', default='testrun', type=str)\n",
    "parser.add_argument('--set_seed', default= 1 , type=int)\n",
    "parser.add_argument('--dset_seed', default= 5 , type=int)\n",
    "parser.add_argument('--active_log', action = 'store_true')\n",
    "\n",
    "parser.add_argument('--pretrain', action = 'store_true')\n",
    "parser.add_argument('--pretrain_epochs', default=50, type=int)\n",
    "parser.add_argument('--pt_tasks', default=['contrastive','denoising'], type=str,nargs='*',choices = ['contrastive','contrastive_sim','denoising'])\n",
    "parser.add_argument('--pt_aug', default=[], type=str,nargs='*',choices = ['mixup','cutmix'])\n",
    "parser.add_argument('--pt_aug_lam', default=0.1, type=float)\n",
    "parser.add_argument('--mixup_lam', default=0.3, type=float)\n",
    "\n",
    "parser.add_argument('--train_mask_prob', default=0, type=float)\n",
    "parser.add_argument('--mask_prob', default=0, type=float)\n",
    "\n",
    "parser.add_argument('--ssl_avail_y', default= 0, type=int)\n",
    "parser.add_argument('--pt_projhead_style', default='diff', type=str,choices = ['diff','same','nohead'])\n",
    "parser.add_argument('--nce_temp', default=0.7, type=float)\n",
    "\n",
    "parser.add_argument('--lam0', default=0.5, type=float)\n",
    "parser.add_argument('--lam1', default=10, type=float)\n",
    "parser.add_argument('--lam2', default=1, type=float)\n",
    "parser.add_argument('--lam3', default=10, type=float)\n",
    "parser.add_argument('--final_mlp_style', default='sep', type=str,choices = ['common','sep'])\n",
    "\n",
    "\n",
    "opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.attention_heads = min(4, opt.attention_heads)\n",
    "opt.attention_dropout = 0.8\n",
    "opt.embedding_size = min(32, opt.embedding_size)\n",
    "opt.ff_dropout = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(opt)\n",
    "#for regression this is the output dimension\n",
    "= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the con_idxs and cat_idxs\n",
    "\n",
    "cont_idxs = [i for i in range(X_train.shape[1]) if i not in cat_idxs]\n",
    "print(cont_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = np.array(X_train_d['data'][:,cont_idxs],dtype=np.float32).mean(0), np.array(X_train_d['data'][:,cont_idxs],dtype=np.float32).std(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_dims= (1115, 7, 2, 4, 2, 4, 3, 2)\n",
      "num_continuous = 9\n",
      "dim = 32\n",
      "dim_out = 1\n",
      "depth = 1\n",
      "heads = 4\n",
      "attn_dropout = 0.8\n",
      "ff_dropout = 0.8\n",
      "mlp_hidden_mults = (4, 2)\n",
      "cont_embeddings = MLP\n",
      "attentiontype = colrow\n",
      "final_mlp_style = sep\n",
      "y_dim = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"cat_dims=\", tuple(cat_dims) )\n",
    "print(\"num_continuous =\", len(cont_idxs))\n",
    "print(\"dim =\", opt.embedding_size)\n",
    "print(\"dim_out =\", 1)\n",
    "print(\"depth =\", opt.transformer_depth)\n",
    "print(\"heads =\", opt.attention_heads)\n",
    "print(\"attn_dropout =\", opt.attention_dropout)\n",
    "print(\"ff_dropout =\", opt.ff_dropout)\n",
    "print(\"mlp_hidden_mults =\", (4, 2))\n",
    "print(\"cont_embeddings =\", opt.cont_embeddings)\n",
    "print(\"attentiontype =\", opt.attentiontype)\n",
    "print(\"final_mlp_style =\", opt.final_mlp_style)\n",
    "print(\"y_dim =\", y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt)\n",
    "model = SAINT(categories = tuple(cat_dims), \n",
    "                num_continuous = len(cont_idxs),                \n",
    "                dim = opt.embedding_size,                           \n",
    "                dim_out = 1,                       \n",
    "                depth = opt.transformer_depth,                       \n",
    "                heads = opt.attention_heads,                         \n",
    "                attn_dropout = opt.attention_dropout,             \n",
    "                ff_dropout = opt.ff_dropout,                  \n",
    "                mlp_hidden_mults = (4, 2),       \n",
    "                cont_embeddings = opt.cont_embeddings,\n",
    "                attentiontype = opt.attentiontype,\n",
    "                final_mlp_style = opt.final_mlp_style,\n",
    "                y_dim = y_dim\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to(device)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing the optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if opt.optimizer == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=opt.lr,\n",
    "                          momentum=0.9, weight_decay=5e-4)\n",
    "    from utils import get_scheduler\n",
    "    scheduler = get_scheduler(opt, optimizer)\n",
    "elif opt.optimizer == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(),lr=opt.lr)\n",
    "elif opt.optimizer == 'AdamW':\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=opt.lr)\n",
    "best_valid_auroc = 0\n",
    "best_valid_accuracy = 0\n",
    "best_test_auroc = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_rmse = 100000\n",
    "print('Using the optimizer: ', opt.optimizer)\n",
    "print('Training begins now.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_openml import DataSetCatCon\n",
    "\n",
    "continuous_mean_std = np.array([train_mean, train_std]).astype(np.float32) \n",
    "\n",
    "train_ds = DataSetCatCon(X_train_d, y_train_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "trainloader = DataLoader(train_ds, batch_size=opt.batchsize, shuffle=True)\n",
    "\n",
    "valid_ds = DataSetCatCon(X_valid_d, y_valid_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "validloader = DataLoader(valid_ds, batch_size=opt.batchsize, shuffle=False)\n",
    "\n",
    "test_ds = DataSetCatCon(X_test_d, y_test_d, cat_idxs, task='regression', continuous_mean_std=continuous_mean_std)\n",
    "testloader = DataLoader(test_ds, batch_size=opt.batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentations import embed_data_mask\n",
    "from utils import count_parameters, classification_scores, mean_sq_error\n",
    "import os\n",
    "\n",
    "modelsave_path = os.path.join(opt.savemodelroot,opt.run_name)\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        optimizer.zero_grad()\n",
    "        # x_categ is the the categorical data, x_cont has continuous data, y_gts has ground truth ys. cat_mask is an array of ones same shape as x_categ and an additional column(corresponding to CLS token) set to 0s. con_mask is an array of ones same shape as x_cont. \n",
    "        x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
    "\n",
    "        # We are converting the data to embeddings in the next step\n",
    "        _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model)           \n",
    "        reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "        # select only the representations corresponding to CLS token and apply mlp on it in the next step to get the predictions.\n",
    "        y_reps = reps[:,0,:]\n",
    "        \n",
    "        y_outs = model.mlpfory(y_reps)\n",
    "        if opt.task == 'regression':\n",
    "            loss = criterion(y_outs,y_gts) \n",
    "        else:\n",
    "            loss = criterion(y_outs,y_gts.squeeze()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if opt.optimizer == 'SGD':\n",
    "            scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "    # print(running_loss)\n",
    "    if opt.active_log:\n",
    "        wandb.log({'epoch': epoch ,'train_epoch_loss': running_loss, \n",
    "        'loss': loss.item()\n",
    "        })\n",
    "    if epoch%5==0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                if opt.task in ['binary','multiclass']:\n",
    "                    accuracy, auroc = classification_scores(model, validloader, device)\n",
    "                    test_accuracy, test_auroc = classification_scores(model, testloader, device)\n",
    "\n",
    "                    print('[EPOCH %d] VALID ACCURACY: %.3f, VALID AUROC: %.3f' %\n",
    "                        (epoch + 1, accuracy,auroc ))\n",
    "                    print('[EPOCH %d] TEST ACCURACY: %.3f, TEST AUROC: %.3f' %\n",
    "                        (epoch + 1, test_accuracy,test_auroc ))\n",
    "                    if opt.active_log:\n",
    "                        wandb.log({'valid_accuracy': accuracy ,'valid_auroc': auroc })     \n",
    "                        wandb.log({'test_accuracy': test_accuracy ,'test_auroc': test_auroc })  \n",
    "                    if opt.task =='multiclass':\n",
    "                        if accuracy > best_valid_accuracy:\n",
    "                            best_valid_accuracy = accuracy\n",
    "                            best_test_auroc = test_auroc\n",
    "                            best_test_accuracy = test_accuracy\n",
    "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
    "                    else:\n",
    "                        if accuracy > best_valid_accuracy:\n",
    "                            best_valid_accuracy = accuracy\n",
    "                        # if auroc > best_valid_auroc:\n",
    "                        #     best_valid_auroc = auroc\n",
    "                            best_test_auroc = test_auroc\n",
    "                            best_test_accuracy = test_accuracy               \n",
    "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
    "\n",
    "                else:\n",
    "                    valid_rmse = mean_sq_error(model, validloader, device)    \n",
    "                    test_rmse = mean_sq_error(model, testloader, device)  \n",
    "                    print('[EPOCH %d] VALID RMSE: %.3f' %\n",
    "                        (epoch + 1, valid_rmse ))\n",
    "                    print('[EPOCH %d] TEST RMSE: %.3f' %\n",
    "                        (epoch + 1, test_rmse ))\n",
    "                    if opt.active_log:\n",
    "                        wandb.log({'valid_rmse': valid_rmse ,'test_rmse': test_rmse })     \n",
    "                    if valid_rmse < best_valid_rmse:\n",
    "                        best_valid_rmse = valid_rmse\n",
    "                        best_test_rmse = test_rmse\n",
    "                        torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvRossmann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
