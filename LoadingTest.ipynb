{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import SAINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load bestmodel.pth\n",
    "\n",
    "model = SAINT(categories = (1, 1115, 7, 2, 4, 2, 4, 3, 2),\n",
    "                num_continuous = 9,                \n",
    "                dim = 32,                           \n",
    "                dim_out = 1,                       \n",
    "                depth = 6,                       \n",
    "                heads = 3,                         \n",
    "                attn_dropout = 0.8,             \n",
    "                ff_dropout = 0.8,                  \n",
    "                mlp_hidden_mults = (4, 2),       \n",
    "                cont_embeddings = 'MLP',\n",
    "                attentiontype = 'colrow',\n",
    "                final_mlp_style = 'sep',\n",
    "                y_dim = 1\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (norm): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
       "  (simple_MLP): ModuleList(\n",
       "    (0): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=32, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer): RowColTransformer(\n",
       "    (embeds): Embedding(1140, 32)\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=32, out_features=144, bias=False)\n",
       "              (to_out): Linear(in_features=48, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=576, out_features=576, bias=False)\n",
       "              (to_out): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((576,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=576, out_features=4608, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=2304, out_features=576, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mask_embed): Embedding(18, 32)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=288, bias=True)\n",
       "      (1): Linear(in_features=288, out_features=144, bias=True)\n",
       "      (2): Linear(in_features=144, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (embeds): Embedding(1140, 32)\n",
       "  (mask_embeds_cat): Embedding(18, 32)\n",
       "  (mask_embeds_cont): Embedding(18, 32)\n",
       "  (single_mask): Embedding(2, 32)\n",
       "  (pos_encodings): Embedding(18, 32)\n",
       "  (mlp1): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1115, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=7, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp2): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=160, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlpfory): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=1000, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=691, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=691, out_features=288, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp2): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=691, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=691, out_features=288, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model from the best model\n",
    "\n",
    "model.load_state_dict(torch.load('/home/coenraadmiddel/Documents/RossmannStoreSales/SAINT/saint/bestmodels/testrun/bestmodel.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saint_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
