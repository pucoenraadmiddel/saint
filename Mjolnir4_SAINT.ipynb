{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in only the first 10000 rows:\n",
    "df = pd.read_parquet('df_post.parquet')\n",
    "#adding POL_TheftClaimRecency\n",
    "\n",
    "#Done in the preprocessor.\n",
    "# df['POL_TheftClaimRecency_ORD'] = pd.to_numeric(df['POL_TheftClaimRecency']).copy(deep=True)\n",
    "\n",
    "# df['POL_TheftClaimRecency_CAT'] = 'LESS'\n",
    "# catlist = [8, '8', '8.0']\n",
    "\n",
    "# df['POL_TheftClaimRecency_CAT'] = df['POL_TheftClaimRecency_CAT'].mask(df['POL_TheftClaimRecency_ORD'].isin(catlist), 'MORE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frequency'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as pp  \n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pp.Preprocessor(df, target_col = 'Acc_GrossClaim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frequency'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.df['Acc_GrossClaimClipped'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.df['Acc_GrossClaim'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifact = run.use_artifact('middelman/catboost_rossmann_mse/catboost_regressor:v34', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "\n",
    "saint_project_name = \"middelman/saint_rossmann_mse\"\n",
    "saint_metric_name = \"orig_valid_rmse\"\n",
    "\n",
    "saint_runs = api.runs(saint_project_name)\n",
    "\n",
    "saint_sorted_runs = sorted(saint_runs, key=lambda r: r.summary.get(saint_metric_name, float('inf')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saint_best_run = saint_sorted_runs[0]\n",
    "import pprint\n",
    "pprint.pprint(saint_best_run.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = saint_best_run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update opt patience to 5\n",
    "opt['patience'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SAINT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_idxs = pre.cat_idxs\n",
    "cat_dims = pre.cat_dims\n",
    "cont_idxs = pre.ord_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dims_saint = np.append(np.array([1]), np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using {}\".format(device))\n",
    "\n",
    "model = SAINT(categories = tuple(cat_dims_saint), \n",
    "            num_continuous = len(cont_idxs),                \n",
    "            dim = opt['embedding_size'],                           \n",
    "            dim_out = 1,                       \n",
    "            depth = opt['transformer_depth'],                       \n",
    "            heads = opt['attention_heads'],                         \n",
    "            attn_dropout = opt['attention_dropout'],             \n",
    "            ff_dropout = opt['ff_dropout'],                  \n",
    "            mlp_hidden_mults = (4, 2),       \n",
    "            cont_embeddings = opt['cont_embeddings'],\n",
    "            attentiontype = opt['attentiontype'],\n",
    "            final_mlp_style = opt['final_mlp_style'],\n",
    "            y_dim = 1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# criterion = nn.MSELoss().to(device)\n",
    "criterion = nn.PoissonNLLLoss().to(device)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters()\n",
    "                        # , lr=opt['lr']\n",
    "                        , lr = 0.00005\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentations import embed_data_mask\n",
    "from utils import count_parameters, classification_scores, mean_sq_error, get_loss\n",
    "import os\n",
    "vision_dset = opt['vision_dset']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "i = 1\n",
    "run = wandb.init(project=\"mjolnir_saint_rmse\", entity=\"middelman\", group='poisson', name=\"saint_rev1_\"+str(i/5*100) + '%_of_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.df[pre.target_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.df[pre.target_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.df[pre.target_col].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.df[pre.target_col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    early_stop_count = 0\n",
    "    for n in np.arange(1, 2, 1):\n",
    "        print(f'Loading only the first {i/5*100}% of training data')\n",
    "        # run = wandb.init(project=\"mjolnir_saint_rmse\", entity=\"middelman\", group='poisson', name=\"saint_rev0_\"+str(i/5*100) + '%_of_data')\n",
    "        trainloader, validloader, testloader = pre.preprocess_for_saint(batch_size = opt['batchsize'], load_percentage = i/5)\n",
    "        best_valid_auroc = 0\n",
    "        best_valid_accuracy = 0\n",
    "        best_test_auroc = 0\n",
    "        best_test_accuracy = 0\n",
    "        best_valid_rmse = 100000\n",
    "        best_valid_nllloss = 100000\n",
    "        print('Using the optimizer: ', opt['optimizer'])\n",
    "        print('Training begins now.')\n",
    "        for epoch in range(opt['epochs']):\n",
    "            print('Starting epoch: ', epoch)\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for _, data in enumerate(trainloader, 0):\n",
    "                optimizer.zero_grad()\n",
    "                # x_categ is the the categorical data, x_cont has continuous data, y_gts has ground truth ys. cat_mask is an array of ones same shape as x_categ and an additional column(corresponding to CLS token) set to 0s. con_mask is an array of ones same shape as x_cont. \n",
    "                x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device), data[2].to(device), data[3].to(device), data[4].to(device)\n",
    "\n",
    "                # We are converting the data to embeddings in the next step\n",
    "                _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model)           \n",
    "                reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "                # select only the representations corresponding to CLS token and apply mlp on it in the next step to get the predictions.\n",
    "                y_reps = reps[:,0,:]\n",
    "                \n",
    "                y_outs = model.mlpfory(y_reps)\n",
    "                if opt['task'] == 'regression':\n",
    "                    loss = criterion(y_outs, y_gts) \n",
    "                else:\n",
    "                    loss = criterion(y_outs,y_gts.squeeze()) \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # print(running_loss)\n",
    "                if opt['active_log']:\n",
    "                    wandb.log({'epoch': epoch ,'running_loss': running_loss, \n",
    "                    'train_loss': loss.item()\n",
    "                    })\n",
    "                print('Loss: ', loss.item())\n",
    "                # if epoch%1==0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    #Get validation loss\n",
    "                    valid_loss = get_loss(model, validloader, device, criterion)\n",
    "                    test_loss = get_loss(model, testloader, device, criterion)\n",
    "                    if opt['active_log']:\n",
    "                        wandb.log(\n",
    "                            {'epoch': epoch,\n",
    "                        'valid_loss': valid_loss.item(),\n",
    "                        'test_loss': test_loss.item()\n",
    "                            }\n",
    "                        )\n",
    "                    \n",
    "                    print('Valid loss: ', valid_loss.item())\n",
    "                    print('Test loss: ', test_loss.item())\n",
    "                    \n",
    "                    if valid_loss.item() < best_valid_nllloss:\n",
    "                        best_valid_nllloss = valid_loss.item()\n",
    "                        \n",
    "                        #get the run id from wandb\n",
    "                        run_id = wandb.run.id\n",
    "                        torch.save(model.state_dict(), f'models/mjolnir4/SAINT_model_best_{run_id}.pt')\n",
    "                        #Save as artifact on weights and biases\n",
    "                        artifact = wandb.Artifact(f'SAINT_model_best_{run_id}', type='model')\n",
    "                        #add the run id to the artifact                       \n",
    "                        # wandb.run.log_artifact(artifact)\n",
    "                        early_stop_count = 0\n",
    "                    else:\n",
    "                        early_stop_count += 1\n",
    "                        print(f\"Early stopping counter: {early_stop_count}/{opt['patience']}\")\n",
    "                        if early_stop_count >= opt['patience']:\n",
    "                            print('EARLY STOPPING')\n",
    "                            break\n",
    "                    model.train()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt['patience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "\n",
    "if run:\n",
    "    for i in np.arange(4, 6, 1):\n",
    "        print(f'Loading only the first {i/5*100}% of training data')\n",
    "        run = wandb.init(project=\"mjolnir_saint_rmse\", entity=\"middelman\", name=\"saint_rev0_\"+str(i/5*100) + '%_of_data')\n",
    "        trainloader, validloader, testloader = pre.preprocess_for_saint(batch_size = opt['batchsize'], load_percentage = i/5)\n",
    "        best_valid_auroc = 0\n",
    "        best_valid_accuracy = 0\n",
    "        best_test_auroc = 0\n",
    "        best_test_accuracy = 0\n",
    "        best_valid_rmse = 100000\n",
    "        print('Using the optimizer: ', opt['optimizer'])\n",
    "        print('Training begins now.')\n",
    "        early_stop_count = 0\n",
    "        for epoch in range(opt['epochs']):\n",
    "            print('Starting epoch: ', epoch)\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                optimizer.zero_grad()\n",
    "                # x_categ is the the categorical data, x_cont has continuous data, y_gts has ground truth ys. cat_mask is an array of ones same shape as x_categ and an additional column(corresponding to CLS token) set to 0s. con_mask is an array of ones same shape as x_cont. \n",
    "                x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device), data[2].to(device), data[3].to(device), data[4].to(device)\n",
    "\n",
    "                # We are converting the data to embeddings in the next step\n",
    "                _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model)           \n",
    "                reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "                # select only the representations corresponding to CLS token and apply mlp on it in the next step to get the predictions.\n",
    "                y_reps = reps[:,0,:]\n",
    "                \n",
    "                y_outs = model.mlpfory(y_reps)\n",
    "                if opt['task'] == 'regression':\n",
    "                    loss = criterion(y_outs, y_gts) \n",
    "                else:\n",
    "                    loss = criterion(y_outs,y_gts.squeeze()) \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            # print(running_loss)\n",
    "            if opt['active_log']:\n",
    "                wandb.log({'epoch': epoch ,'train_epoch_loss': running_loss, \n",
    "                'loss': loss.item()\n",
    "                })\n",
    "            if epoch%1==0:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        valid_rmse = mean_sq_error(model, validloader, device, vision_dset)    \n",
    "                        test_rmse = mean_sq_error(model, testloader, device, vision_dset)  \n",
    "                        train_rmse = mean_sq_error(model, trainloader, device, vision_dset)  \n",
    "                        print('[EPOCH %d] VALID RMSE: %.3f' %\n",
    "                            (epoch + 1, valid_rmse))# , orig_valid_rmse ))\n",
    "                        print('[EPOCH %d] TEST RMSE: %.3f' %\n",
    "                            (epoch + 1, test_rmse))#, orig_test_rmse ))\n",
    "                        print('[EPOCH %d] TRAIN RMSE: %.3f' %\n",
    "                            (epoch + 1, train_rmse)) #, orig_train_rmse ))\n",
    "                        \n",
    "                        if opt['active_log']:\n",
    "                            wandb.log({'valid_rmse': valid_rmse\n",
    "                                        , 'test_rmse': test_rmse\n",
    "                                        , 'train_rmse': train_rmse\n",
    "                                        # , 'orig_valid_rmse': orig_valid_rmse\n",
    "                                        # , 'orig_test_rmse': orig_test_rmse\n",
    "                                        # , 'orig_train_rmse': orig_train_rmse \n",
    "                                        })     \n",
    "                        if valid_rmse < best_valid_rmse:\n",
    "                            best_valid_rmse = valid_rmse\n",
    "                            best_test_rmse = test_rmse\n",
    "                            best_train_rmse = train_rmse\n",
    "                            \n",
    "                            #get the run id from wandb\n",
    "                            run_id = wandb.run.id\n",
    "                            torch.save(model.state_dict(), f'models/mjolnir4/SAINT_model_best_{run_id}.pt')\n",
    "                            #Save as artifact on weights and biases\n",
    "                            artifact = wandb.Artifact(f'SAINT_model_best_{run_id}', type='model')\n",
    "                            #add the run id to the artifact                       \n",
    "                            wandb.run.log_artifact(artifact)\n",
    "                            early_stop_count = 0\n",
    "                        else:\n",
    "                            early_stop_count += 1\n",
    "                            print(f\"Early stopping counter: {early_stop_count}/{opt['patience']}\")\n",
    "                            if early_stop_count >= opt['patience']:\n",
    "                                print('EARLY STOPPING')\n",
    "                                break\n",
    "                    model.train()\n",
    "        \n",
    "        del trainloader\n",
    "        del validloader\n",
    "        del testloader\n",
    "        del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('df_post.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Acc_GrossClaim'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1276544/6050571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Acc_GrossClaim'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('df_post.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saint_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
